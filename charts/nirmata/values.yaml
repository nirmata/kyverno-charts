# -- Internal settings used with `helm template` to generate install manifest
# @ignored
templating:
  enabled: false
  debug: false
  version: ~

global:
  image:
    # -- (string) Global value that allows to set a single image registry across all deployments.
    # When set, it will override any values set under `.image.registry` across the chart.
    registry: ~

# -- (string) Override the name of the chart
nameOverride: ~

# -- (string) Override the expanded name of the chart
fullnameOverride: ~

# -- (string) Override the namespace the chart deploys to
namespaceOverride: ~

apiVersionOverride:
  # -- (string) Override api version used to create `PodDisruptionBudget`` resources.
  # When not specified the chart will check if `policy/v1/PodDisruptionBudget` is available to
  # determine the api version automatically.
  podDisruptionBudget: ~

# CRDs configuration
crds:

  backgroundscanreports: true

  cleanuppolicies: true

  clusterbackgroundscanreports: true

  clustercleanuppolicies: true

  clusterpolicyreports: true

  policyreports: true

# While disabling controllers in their respective configuration, disable them here as well
# This is temporary and will be fixed in a few versions

  reportsController:
    enabled: true

  cleanupController:
    enabled: true

  backgroundController:
    enabled: true

  # -- Whether to have Helm install the Kyverno CRDs, if the CRDs are not installed by Helm, they must be added before policies can be created
  install: true

  # -- Additional CRDs annotations
  annotations: {}
    # argocd.argoproj.io/sync-options: Replace=true
    # strategy.spinnaker.io/replace: 'true'

  # -- Additional CRDs labels
  customLabels: {}

# Configuration
config:

  # -- Create the configmap.
  create: true
  serviceAccount:
    # -- Create a ServiceAccount
    create: true
    # -- The ServiceAccount name
    name:
    # -- Annotations for the ServiceAccount
    annotations: {}
      # example.com/annotation: value

image:
  # -- Image registry
  registry:
  # If you want to manage the registry you should remove it from the repository
  # registry: ghcr.io
  # repository: kyverno/kyverno
  # -- Image repository
  repository: ghcr.io/nirmata/kyverno
  # -- Image tag
  # Defaults to appVersion in Chart.yaml if omitted
  tag: v1.9.5-n4k.nirmata.4
  # -- Image pull policy
  pullPolicy: IfNotPresent
  # -- Image pull secrets
  pullSecrets:
  - name: image-pull-secret
initImage:
  # -- Image registry
  registry:
  # If you want to manage the registry you should remove it from the repository
  # registry: ghcr.io
  # repository: kyverno/kyvernopre
  # -- Image repository
  repository: ghcr.io/nirmata/kyvernopre
  # -- Image tag
  # If initImage.tag is missing, defaults to image.tag
  tag: v1.9.5-n4k.nirmata.4
  # -- Image pull policy
  # If initImage.pullPolicy is missing, defaults to image.pullPolicy
  pullPolicy:

initContainer:
  # -- Extra arguments to give to the kyvernopre binary.
  extraArgs:
    - --loggingFormat=text

  # -- (string) The configmap name (required if `create` is `false`).
  name: ~

  # -- Additional annotations to add to the configmap.
  annotations: {}

  # -- Enable registry mutation for container images. Enabled by default.
  enableDefaultRegistryMutation: true

  # -- The registry hostname used for the image mutation.
  defaultRegistry: docker.io

  # -- Exclude groups
  excludeGroups:
    - system:serviceaccounts:kube-system
    - system:nodes

  # -- Exclude usernames
  excludeUsernames: []
    # - system:kube-scheduler

  # -- Exclude roles
  excludeRoles: []

  # -- Exclude roles
  excludeClusterRoles: []

  # -- Generate success events.
  generateSuccessEvents: false

  # -- Resource types to be skipped by the Kyverno policy engine.
  # Make sure to surround each entry in quotes so that it doesn't get parsed as a nested YAML list.
  # These are joined together without spaces, run through `tpl`, and the result is set in the config map.
  # @default -- See [values.yaml](values.yaml)
  resourceFilters:
    - '[Event,*,*]'
    - '[*/*,kube-system,*]'
    - '[*/*,kube-public,*]'
    - '[*/*,kube-node-lease,*]'
    - '[Node,*,*]'
    - '[Node/*,*,*]'
    - '[APIService,*,*]'
    - '[APIService/*,*,*]'
    - '[TokenReview,*,*]'
    - '[SubjectAccessReview,*,*]'
    - '[SelfSubjectAccessReview,*,*]'
    - '[Binding,*,*]'
    - '[Pod/binding,*,*]'
    - '[ReplicaSet,*,*]'
    - '[ReplicaSet/*,*,*]'
    - '[AdmissionReport,*,*]'
    - '[AdmissionReport/*,*,*]'
    - '[ClusterAdmissionReport,*,*]'
    - '[ClusterAdmissionReport/*,*,*]'
    - '[BackgroundScanReport,*,*]'
    - '[BackgroundScanReport/*,*,*]'
    - '[ClusterBackgroundScanReport,*,*]'
    - '[ClusterBackgroundScanReport/*,*,*]'
    # exclude resources from the chart
    - '[ClusterRole,*,{{ template "kyverno.admission-controller.roleName" . }}]'
    - '[ClusterRole,*,{{ template "kyverno.admission-controller.roleName" . }}:core]'
    - '[ClusterRole,*,{{ template "kyverno.admission-controller.roleName" . }}:additional]'
    - '[ClusterRole,*,{{ template "kyverno.background-controller.roleName" . }}]'
    - '[ClusterRole,*,{{ template "kyverno.background-controller.roleName" . }}:core]'
    - '[ClusterRole,*,{{ template "kyverno.background-controller.roleName" . }}:additional]'
    - '[ClusterRole,*,{{ template "kyverno.cleanup-controller.roleName" . }}]'
    - '[ClusterRole,*,{{ template "kyverno.cleanup-controller.roleName" . }}:core]'
    - '[ClusterRole,*,{{ template "kyverno.cleanup-controller.roleName" . }}:additional]'
    - '[ClusterRole,*,{{ template "kyverno.reports-controller.roleName" . }}]'
    - '[ClusterRole,*,{{ template "kyverno.reports-controller.roleName" . }}:core]'
    - '[ClusterRole,*,{{ template "kyverno.reports-controller.roleName" . }}:additional]'
    - '[ClusterRoleBinding,*,{{ template "kyverno.admission-controller.roleName" . }}]'
    - '[ClusterRoleBinding,*,{{ template "kyverno.background-controller.roleName" . }}]'
    - '[ClusterRoleBinding,*,{{ template "kyverno.cleanup-controller.roleName" . }}]'
    - '[ClusterRoleBinding,*,{{ template "kyverno.reports-controller.roleName" . }}]'
    - '[ServiceAccount,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.serviceAccountName" . }}]'
    - '[ServiceAccount/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.serviceAccountName" . }}]'
    - '[ServiceAccount,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.serviceAccountName" . }}]'
    - '[ServiceAccount/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.serviceAccountName" . }}]'
    - '[ServiceAccount,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.serviceAccountName" . }}]'
    - '[ServiceAccount/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.serviceAccountName" . }}]'
    - '[ServiceAccount,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.serviceAccountName" . }}]'
    - '[ServiceAccount/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.serviceAccountName" . }}]'
    - '[Role,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.roleName" . }}]'
    - '[Role,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.roleName" . }}]'
    - '[Role,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.roleName" . }}]'
    - '[Role,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.roleName" . }}]'
    - '[RoleBinding,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.roleName" . }}]'
    - '[RoleBinding,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.roleName" . }}]'
    - '[RoleBinding,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.roleName" . }}]'
    - '[RoleBinding,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.roleName" . }}]'
    - '[ConfigMap,{{ include "kyverno.namespace" . }},{{ template "kyverno.config.configMapName" . }}]'
    - '[ConfigMap,{{ include "kyverno.namespace" . }},{{ template "kyverno.config.metricsConfigMapName" . }}]'
    - '[Deployment,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.name" . }}]'
    - '[Deployment/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.name" . }}]'
    - '[Deployment,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.name" . }}]'
    - '[Deployment/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.name" . }}]'
    - '[Deployment,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}]'
    - '[Deployment/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}]'
    - '[Deployment,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.name" . }}]'
    - '[Deployment/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.name" . }}]'
    - '[Pod,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.name" . }}-*]'
    - '[Pod/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.name" . }}-*]'
    - '[Pod,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.name" . }}-*]'
    - '[Pod/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.name" . }}-*]'
    - '[Pod,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}-*]'
    - '[Pod/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}-*]'
    - '[Pod,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.name" . }}-*]'
    - '[Pod/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.name" . }}-*]'
    - '[Job,{{ include "kyverno.namespace" . }},{{ template "kyverno.fullname" . }}-hook-pre-delete]'
    - '[Job/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.fullname" . }}-hook-pre-delete]'
    - '[NetworkPolicy,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.name" . }}]'
    - '[NetworkPolicy/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.name" . }}]'
    - '[NetworkPolicy,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.name" . }}]'
    - '[NetworkPolicy/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.name" . }}]'
    - '[NetworkPolicy,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}]'
    - '[NetworkPolicy/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}]'
    - '[NetworkPolicy,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.name" . }}]'
    - '[NetworkPolicy/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.name" . }}]'
    - '[PodDisruptionBudget,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.name" . }}]'
    - '[PodDisruptionBudget/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.name" . }}]'
    - '[PodDisruptionBudget,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.name" . }}]'
    - '[PodDisruptionBudget/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.name" . }}]'
    - '[PodDisruptionBudget,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}]'
    - '[PodDisruptionBudget/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}]'
    - '[PodDisruptionBudget,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.name" . }}]'
    - '[PodDisruptionBudget/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.name" . }}]'
    - '[Service,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.serviceName" . }}]'
    - '[Service/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.serviceName" . }}]'
    - '[Service,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.serviceName" . }}-metrics]'
    - '[Service/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.serviceName" . }}-metrics]'
    - '[Service,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.name" . }}-metrics]'
    - '[Service/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.background-controller.name" . }}-metrics]'
    - '[Service,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}]'
    - '[Service/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}]'
    - '[Service,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}-metrics]'
    - '[Service/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}-metrics]'
    - '[Service,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.name" . }}-metrics]'
    - '[Service/*,{{ include "kyverno.namespace" . }},{{ template "kyverno.reports-controller.name" . }}-metrics]'
    - '[ServiceMonitor,{{ if .Values.admissionController.serviceMonitor.namespace }}{{ .Values.admissionController.serviceMonitor.namespace }}{{ else }}{{ template "kyverno.namespace" . }}{{ end }},{{ template "kyverno.admission-controller.name" . }}]'
    - '[ServiceMonitor,{{ if .Values.admissionController.serviceMonitor.namespace }}{{ .Values.admissionController.serviceMonitor.namespace }}{{ else }}{{ template "kyverno.namespace" . }}{{ end }},{{ template "kyverno.background-controller.name" . }}]'
    - '[ServiceMonitor,{{ if .Values.admissionController.serviceMonitor.namespace }}{{ .Values.admissionController.serviceMonitor.namespace }}{{ else }}{{ template "kyverno.namespace" . }}{{ end }},{{ template "kyverno.cleanup-controller.name" . }}]'
    - '[ServiceMonitor,{{ if .Values.admissionController.serviceMonitor.namespace }}{{ .Values.admissionController.serviceMonitor.namespace }}{{ else }}{{ template "kyverno.namespace" . }}{{ end }},{{ template "kyverno.reports-controller.name" . }}]'
    - '[Secret,{{ include "kyverno.namespace" . }},{{ template "kyverno.admission-controller.serviceName" . }}.{{ template "kyverno.namespace" . }}.svc.*]'
    - '[Secret,{{ include "kyverno.namespace" . }},{{ template "kyverno.cleanup-controller.name" . }}.{{ template "kyverno.namespace" . }}.svc.*]'

  # -- Defines the `namespaceSelector` in the webhook configurations.
  # Note that it takes a list of `namespaceSelector` and/or `objectSelector` in the JSON format, and only the first element
  # will be forwarded to the webhook configurations.
  # The Kyverno namespace is excluded if `excludeKyvernoNamespace` is `true` (default)
  webhooks: []
    # Exclude namespaces
    # - namespaceSelector:
    #     matchExpressions:
    #     - key: kubernetes.io/metadata.name
    #       operator: NotIn
    #       values:
    #         - kube-system
    #         - kyverno
    # Exclude objects
    # - objectSelector:
    #     matchExpressions:
    #     - key: webhooks.kyverno.io/exclude
    #       operator: DoesNotExist

  # -- Defines annotations to set on webhook configurations.
  webhookAnnotations: {}
    # Example to disable admission enforcer on AKS:
    # 'admissions.enforcer/disabled': 'true'

  # -- Defines match conditions to set on webhook configurations (requires Kubernetes 1.27+).
  matchConditions: []

  # -- Exclude Kyverno namespace
  # Determines if default Kyverno namespace exclusion is enabled for webhooks and resourceFilters
  excludeKyvernoNamespace: true

  # -- resourceFilter namespace exclude
  # Namespaces to exclude from the default resourceFilters
  resourceFiltersExcludeNamespaces: []

# Metrics configuration
metricsConfig:

  # -- Create the configmap.
  create: true

  # -- (string) The configmap name (required if `create` is `false`).
  name: ~

  # -- Additional annotations to add to the configmap.
  annotations: {}

  namespaces:

    # -- List of namespaces to capture metrics for.
    include: []

    # -- list of namespaces to NOT capture metrics for.
    exclude: []

  # -- (string) Rate at which metrics should reset so as to clean up the memory footprint of kyverno metrics, if you might be expecting high memory footprint of Kyverno's metrics. Default: 0, no refresh of metrics
  metricsRefreshInterval: ~
    # metricsRefreshInterval: 24h

  # -- (list) Configures the bucket boundaries for all Histogram metrics, changing this configuration requires restart of the kyverno admission controller
  bucketBoundaries: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 15, 20, 25, 30]

  # -- (map) Configures the exposure of individual metrics, by default all metrics and all labels are exported, changing this configuration requires restart of the kyverno admission controller
  metricsExposure: ~
  # metricsExposure:
  #   kyverno_policy_execution_duration_seconds:
  #     disabledLabelDimensions: ["resource_kind", "resource_namespace", "resource_request_operation"]
  #     bucketBoundaries: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5]
  #   kyverno_admission_review_duration_seconds:
  #     enabled: false

# -- Image pull secrets for image verification policies, this will define the `--imagePullSecrets` argument
imagePullSecrets: {}
  # regcred:
  #   registry: foo.example.com
  #   username: foobar
  #   password: secret
  # regcred2:
  #   registry: bar.example.com
  #   username: barbaz
  #   password: secret2

# -- Existing Image pull secrets for image verification policies, this will define the `--imagePullSecrets` argument
existingImagePullSecrets: []
  # - test-registry
  # - other-test-registry

# Tests configuration
test:

  image:
    # -- (string) Image registry
    registry: ~
    # -- Image repository
    repository: busybox
    # -- Image tag
    # Defaults to `latest` if omitted
    tag: '1.35'
    # -- (string) Image pull policy
    # Defaults to image.pullPolicy if omitted
    pullPolicy: ~

# -- License manager configs
licenseManager:
  # -- Whether to use license manager
  enable: true
  # -- License manager repo
  imageRepository: ghcr.io/nirmata/kyverno-license-manager
  # -- Image tag
  imageTag: v0.1.2
  # -- Product name to be present in license, empty to ignore check
  productName: ""
  # -- Validation interval in mins
  validateIntervalMins: 60
  # -- License server
  callHomeServer: "nirmata.io"
  # -- License key
  licenseKey: "free-tier-license"
  # -- License server API key
  apiKey:
  # -- Cluster Id. If not provided, use kube-system uid
  clusterId:
  # -- Cluster name. Autogenerated if not provided
  clusterName:

  # -- Security context for the pod
  podSecurityContext: {}

  # -- Node labels for pod assignment
  nodeSelector: {}

  # -- List of node taints to tolerate
  tolerations: []

  # -- Pod anti affinity constraints.
  podAntiAffinity: {}

  # -- Pod affinity constraints.
  podAffinity: {}

  # -- Node affinity constraints.
  nodeAffinity: {}

  # -- Security context for the hook containers
  securityContext:
    runAsUser: 65534
    runAsGroup: 65534
    runAsNonRoot: true
    privileged: false
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
    seccompProfile:
      type: RuntimeDefault

grafana:
  # -- Enable grafana dashboard creation.
  enabled: false

  # -- Configmap name template.
  configMapName: '{{ include "kyverno.fullname" . }}-grafana'

  # -- (string) Namespace to create the grafana dashboard configmap.
  # If not set, it will be created in the same namespace where the chart is deployed.
  namespace: ~

  # -- Grafana dashboard configmap annotations.
  annotations: {}

# Admission controller configuration
admissionController:

  rbac:
    # -- Create RBAC resources
    create: true

    serviceAccount:
      # -- The ServiceAccount name
      name:

      # -- Annotations for the ServiceAccount
      annotations: {}
        # example.com/annotation: value

    clusterRole:
      # -- Extra resource permissions to add in the cluster role
      extraResources: []
      # - apiGroups:
      #     - ''
      #   resources:
      #     - pods
      #   verbs:
      #     - create
      #     - update
      #     - delete

  # -- Create self-signed certificates at deployment time.
  # The certificates won't be automatically renewed if this is set to `true`.
  createSelfSignedCert: false

  image:
    # -- Image registry
    registry:
    # If you want to manage the registry you should remove it from the repository
    # registry: ghcr.io
    # repository: kyverno/kyverno
    # -- Image repository
    repository: ghcr.io/nirmata/cleanup-controller  # kyverno: replaced in e2e tests
    # -- Image tag
    # Defaults to appVersion in Chart.yaml if omitted
    tag: v1.9.5-n4k.nirmata.4
    # -- Image pull policy
    pullPolicy: IfNotPresent
    # -- Image pull secrets
    pullSecrets: []
    # - secretName

  # -- (int) Desired number of pods
  replicas: ~

  # -- Additional labels to add to each pod
  podLabels: {}
    # example.com/label: foo

  # -- Additional annotations to add to each pod
  podAnnotations: {}
    # example.com/annotation: foo

  # -- Deployment update strategy.
  # Ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  # @default -- See [values.yaml](values.yaml)
  updateStrategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 40%
    type: RollingUpdate

  # -- Optional priority class
  priorityClassName: ''

  # -- Change `apiPriorityAndFairness` to `true` if you want to insulate the API calls made by Kyverno admission controller activities.
  # This will help ensure Kyverno stability in busy clusters.
  # Ref: https://kubernetes.io/docs/concepts/cluster-administration/flow-control/
  apiPriorityAndFairness: false

  # -- Priority level configuration.
  # The block is directly forwarded into the priorityLevelConfiguration, so you can use whatever specification you want.
  # ref: https://kubernetes.io/docs/concepts/cluster-administration/flow-control/#prioritylevelconfiguration
  # @default -- See [values.yaml](values.yaml)
  priorityLevelConfigurationSpec:
    type: Limited
    limited:
      nominalConcurrencyShares: 10
      limitResponse:
        queuing:
          queueLengthLimit: 50
        type: Queue

  # -- Change `hostNetwork` to `true` when you want the pod to share its host's network namespace.
  # Useful for situations like when you end up dealing with a custom CNI over Amazon EKS.
  # Update the `dnsPolicy` accordingly as well to suit the host network mode.
  hostNetwork: false

  # -- `dnsPolicy` determines the manner in which DNS resolution happens in the cluster.
  # In case of `hostNetwork: true`, usually, the `dnsPolicy` is suitable to be `ClusterFirstWithHostNet`.
  # For further reference: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy.
  dnsPolicy: ClusterFirst

  # -- Startup probe.
  # The block is directly forwarded into the deployment, so you can use whatever startupProbes configuration you want.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  # @default -- See [values.yaml](values.yaml)
  startupProbe:
    httpGet:
      path: /health/liveness
      port: 9443
      scheme: HTTPS
    failureThreshold: 20
    initialDelaySeconds: 2
    periodSeconds: 6

  # -- Liveness probe.
  # The block is directly forwarded into the deployment, so you can use whatever livenessProbe configuration you want.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  # @default -- See [values.yaml](values.yaml)
  livenessProbe:
    httpGet:
      path: /health/liveness
      port: 9443
      scheme: HTTPS
    initialDelaySeconds: 15
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 2
    successThreshold: 1

  # -- Readiness Probe.
  # The block is directly forwarded into the deployment, so you can use whatever readinessProbe configuration you want.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  # @default -- See [values.yaml](values.yaml)
  readinessProbe:
    httpGet:
      path: /health/readiness
      port: 9443
      scheme: HTTPS
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1

  # -- Node labels for pod assignment
  nodeSelector: {}

  # -- List of node taints to tolerate
  tolerations: []

  antiAffinity:
    # -- Pod antiAffinities toggle.
    # Enabled by default but can be disabled if you want to schedule pods to the same node.
    enabled: true

  # -- Pod anti affinity constraints.
  # @default -- See [values.yaml](values.yaml)
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/component
                operator: In
                values:
                  - admission-controller
          topologyKey: kubernetes.io/hostname

  # -- Pod affinity constraints.
  podAffinity: {}

  # -- Node affinity constraints.
  nodeAffinity: {}

  # -- Topology spread constraints.
  topologySpreadConstraints: []

  # -- Security context for the pod
  podSecurityContext: {}

  podDisruptionBudget:
    # -- Enable PodDisruptionBudget.
    # Will always be enabled if replicas > 1. This non-declarative behavior should ideally be avoided, but changing it now would be breaking.
    enabled: false
    # -- Configures the minimum available pods for disruptions.
    # Cannot be used if `maxUnavailable` is set.
    minAvailable: 1
    # -- Configures the maximum unavailable pods for disruptions.
    # Cannot be used if `minAvailable` is set.
    maxUnavailable:

  # -- A writable volume to use for the TUF root initialization.
  tufRootMountPath: /.sigstore

  # -- Volume to be mounted in pods for TUF/cosign work.
  sigstoreVolume:
    emptyDir: {}

  # -- Image pull secrets
  imagePullSecrets: []
    # - secretName

  initContainer:

    image:
      # -- Image registry
      registry: ghcr.io
      # -- Image repository
      repository: nirmata/kyvernopre
      # -- (string) Image tag
      # If missing, defaults to image.tag
      tag: ~
      # -- (string) Image pull policy
      # If missing, defaults to image.pullPolicy
      pullPolicy: ~

    resources:
      # -- Pod resource limits
      limits:
        cpu: 100m
        memory: 256Mi
      # -- Pod resource requests
      requests:
        cpu: 10m
        memory: 64Mi

    # -- Container security context
    securityContext:
      runAsNonRoot: true
      privileged: false
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop:
          - ALL
      seccompProfile:
        type: RuntimeDefault

    # -- Additional container args.
    extraArgs: {}

    # -- Additional container environment variables.
    extraEnvVars: []

  container:

    image:
      # -- Image registry
      registry: ghcr.io
      # -- Image repository
      repository: nirmata/kyverno
      # -- (string) Image tag
      # Defaults to appVersion in Chart.yaml if omitted
      tag: ~
      # -- Image pull policy
      pullPolicy: IfNotPresent

    resources:
      # -- Pod resource limits
      limits:
        memory: 384Mi
      # -- Pod resource requests
      requests:
        cpu: 100m
        memory: 128Mi

    # -- Container security context
    securityContext:
      runAsNonRoot: true
      privileged: false
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop:
          - ALL
      seccompProfile:
        type: RuntimeDefault

    # -- Additional container args.
    extraArgs: {}

    # -- Additional container environment variables.
    extraEnvVars: []

  # -- Array of extra init containers
  extraInitContainers: []
    # - name: init-container
    #   image: busybox
    #   command: ['sh', '-c', 'echo Hello']

  # -- Array of extra containers to run alongside kyverno
  extraContainers: []
    # - name: myapp-container
    #   image: busybox
    #   command: ['sh', '-c', 'echo Hello && sleep 3600']

  service:
    # -- Service port.
    port: 443
    # -- Service type.
    type: ClusterIP
    # -- Service node port.
    # Only used if `type` is `NodePort`.
    nodePort:
    # -- Service annotations.
    annotations: {}

  metricsService:
    # -- Create service.
    create: true
    # -- Service port.
    # Kyverno's metrics server will be exposed at this port.
    port: 8000
    # -- Service type.
    type: ClusterIP
    # -- Service node port.
    # Only used if `type` is `NodePort`.
    nodePort:
    # -- Service annotations.
    annotations: {}

  networkPolicy:
    # -- When true, use a NetworkPolicy to allow ingress to the webhook
    # This is useful on clusters using Calico and/or native k8s network policies in a default-deny setup.
    enabled: false
    # -- A list of valid from selectors according to https://kubernetes.io/docs/concepts/services-networking/network-policies.
    ingressFrom: []

  serviceMonitor:
    # -- Create a `ServiceMonitor` to collect Prometheus metrics.
    enabled: false
    # -- Additional labels
    additionalLabels: {}
    # -- (string) Override namespace
    namespace: ~
    # --  Interval to scrape metrics
    interval: 30s
    # -- Timeout if metrics can't be retrieved in given time interval
    scrapeTimeout: 25s
    # -- Is TLS required for endpoint
    secure: false
    # -- TLS Configuration for endpoint
    tlsConfig: {}
    # -- RelabelConfigs to apply to samples before scraping
    relabelings: []
    # -- MetricRelabelConfigs to apply to samples before ingestion.
    metricRelabelings: []

  tracing:
    # -- Enable tracing
    enabled: false
    # -- Traces receiver address
    address:
    # -- Traces receiver port
    port:
    # -- Traces receiver credentials
    creds: ''

  metering:
    # -- Disable metrics export
    disabled: false
    # -- Otel configuration, can be `prometheus` or `grpc`
    config: prometheus
    # -- Prometheus endpoint port
    port: 8000
    # -- Otel collector endpoint
    collector: ''
    # -- Otel collector credentials
    creds: ''

# Cleanup controller configuration
cleanupController:

  # -- Enable cleanup controller.
  enabled: true

  rbac:
    # -- Create RBAC resources
    create: true

    serviceAccount:
      # -- Service account name
      name:

      # -- Annotations for the ServiceAccount
      annotations: {}
        # example.com/annotation: value

    coreClusterRole:
      # -- Extra resource permissions to add in the core cluster role.
      # This was introduced to avoid breaking change in the chart but should ideally be moved in `clusterRole.extraResources`.
      # @default -- See [values.yaml](values.yaml)
      extraResources:
        - apiGroups:
            - '*'
          resources:
            - '*'
          verbs:
            - get
            - list
            - watch
        - apiGroups:
            - networking.k8s.io
          resources:
            - ingresses
            - ingressclasses
            - networkpolicies
          verbs:
            - create
            - update
            - patch
            - delete
        - apiGroups:
            - rbac.authorization.k8s.io
          resources:
            - rolebindings
            - roles
          verbs:
            - create
            - update
            - patch
            - delete
        - apiGroups:
            - ''
          resources:
            - configmaps
            - secrets
            - resourcequotas
            - limitranges
          verbs:
            - create
            - update
            - patch
            - delete

    clusterRole:
      # -- Extra resource permissions to add in the cluster role
      extraResources: []
      # - apiGroups:
      #     - ''
      #   resources:
      #     - pods

  # -- Create self-signed certificates at deployment time.
  # The certificates won't be automatically renewed if this is set to `true`.
  createSelfSignedCert: false

  image:
    # -- Image registry
    registry: ghcr.io
    # -- Image repository
    repository: nirmata/cleanup-controller
    # -- (string) Image tag
    # Defaults to appVersion in Chart.yaml if omitted
    tag: ~
    # -- Image pull policy
    pullPolicy: IfNotPresent

  # -- Image pull secrets
  imagePullSecrets: []
    # - secretName

  # -- (int) Desired number of pods
  replicas: ~

  # -- Deployment update strategy.
  # Ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  # @default -- See [values.yaml](values.yaml)
  updateStrategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 40%
    type: RollingUpdate

  # -- Optional priority class
  priorityClassName: ''

  # -- Change `hostNetwork` to `true` when you want the pod to share its host's network namespace.
  # Useful for situations like when you end up dealing with a custom CNI over Amazon EKS.
  # Update the `dnsPolicy` accordingly as well to suit the host network mode.
  hostNetwork: false

  # -- `dnsPolicy` determines the manner in which DNS resolution happens in the cluster.
  # In case of `hostNetwork: true`, usually, the `dnsPolicy` is suitable to be `ClusterFirstWithHostNet`.
  # For further reference: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy.
  dnsPolicy: ClusterFirst

  # -- Extra arguments passed to the container on the command line
  extraArgs: {}

  resources:
    # -- Pod resource limits
    limits:
      memory: 128Mi
    # -- Pod resource requests
    requests:
      cpu: 100m
      memory: 64Mi

  # -- Startup probe.
  # The block is directly forwarded into the deployment, so you can use whatever startupProbes configuration you want.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  # @default -- See [values.yaml](values.yaml)
  startupProbe:
    httpGet:
      path: /health/liveness
      port: 9443
      scheme: HTTPS
    failureThreshold: 20
    initialDelaySeconds: 2
    periodSeconds: 6

  # -- Liveness probe.
  # The block is directly forwarded into the deployment, so you can use whatever livenessProbe configuration you want.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  # @default -- See [values.yaml](values.yaml)
  livenessProbe:
    httpGet:
      path: /health/liveness
      port: 9443
      scheme: HTTPS
    initialDelaySeconds: 15
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 2
    successThreshold: 1

  # -- Readiness Probe.
  # The block is directly forwarded into the deployment, so you can use whatever readinessProbe configuration you want.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  # @default -- See [values.yaml](values.yaml)
  readinessProbe:
    httpGet:
      path: /health/readiness
      port: 9443
      scheme: HTTPS
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1

  # -- Node labels for pod assignment
  nodeSelector: {}

  # -- List of node taints to tolerate
  tolerations: []

  antiAffinity:
    # -- Pod antiAffinities toggle.
    # Enabled by default but can be disabled if you want to schedule pods to the same node.
    enabled: true

  # -- Pod anti affinity constraints.
  # @default -- See [values.yaml](values.yaml)
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/component
                operator: In
                values:
                  - cleanup-controller
          topologyKey: kubernetes.io/hostname

  # -- Pod affinity constraints.
  podAffinity: {}

  # -- Node affinity constraints.
  nodeAffinity: {}

  # -- Topology spread constraints.
  topologySpreadConstraints: []

  # -- Security context for the pod
  podSecurityContext: {}

  # -- Security context for the containers
  securityContext:
    runAsNonRoot: true
    privileged: false
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
    seccompProfile:
      type: RuntimeDefault

  podDisruptionBudget:
    # -- Enable PodDisruptionBudget.
    # Will always be enabled if replicas > 1. This non-declarative behavior should ideally be avoided, but changing it now would be breaking.
    enabled: false
    # -- Configures the minimum available pods for disruptions.
    # Cannot be used if `maxUnavailable` is set.
    minAvailable: 1
    # -- Configures the maximum unavailable pods for disruptions.
    # Cannot be used if `minAvailable` is set.
    maxUnavailable:

  service:
    # -- Service port.
    port: 443
    # -- Service type.
    type: ClusterIP
    # -- Service node port.
    # Only used if `service.type` is `NodePort`.
    nodePort:
    # -- Service annotations.
    annotations: {}

  metricsService:
    # -- Create service.
    create: true
    # -- Service port.
    # Metrics server will be exposed at this port.
    port: 8000
    # -- Service type.
    type: ClusterIP
    # -- Service node port.
    # Only used if `metricsService.type` is `NodePort`.
    nodePort:
    # -- Service annotations.
    annotations: {}

  networkPolicy:

    # -- When true, use a NetworkPolicy to allow ingress to the webhook
    # This is useful on clusters using Calico and/or native k8s network policies in a default-deny setup.
    enabled: false

    # -- A list of valid from selectors according to https://kubernetes.io/docs/concepts/services-networking/network-policies.
    ingressFrom: []

  serviceMonitor:
    # -- Create a `ServiceMonitor` to collect Prometheus metrics.
    enabled: false
    # -- Additional labels
    additionalLabels: {}
    # -- (string) Override namespace
    namespace: ~
    # --  Interval to scrape metrics
    interval: 30s
    # -- Timeout if metrics can't be retrieved in given time interval
    scrapeTimeout: 25s
    # -- Is TLS required for endpoint
    secure: false
    # -- TLS Configuration for endpoint
    tlsConfig: {}

  tracing:
    # -- Enable tracing
    enabled: false
    # -- Traces receiver address
    address:
    # -- Traces receiver port
    port:
    # -- Traces receiver credentials
    creds: ''

  logging:
    # -- Logging format
    format: text

  metering:
    # -- Disable metrics export
    disabled: false
    # -- Otel configuration, can be `prometheus` or `grpc`
    config: prometheus
    # -- Prometheus endpoint port
    port: 8000
    # -- Otel collector endpoint
    collector: ''
    # -- Otel collector credentials
    creds: ''

# Reports controller configuration
reportsController:

  # -- Enable reports controller.
  enabled: true

  rbac:
    # -- Create RBAC resources
    create: true

    serviceAccount:
      # -- Service account name
      name:

      # -- Annotations for the ServiceAccount
      annotations: {}
        # example.com/annotation: value

    clusterRole:
      # -- Extra resource permissions to add in the cluster role
      extraResources: []
      # - apiGroups:
      #     - ''
      #   resources:
      #     - pods

  image:
    # -- Image registry
    registry: ghcr.io
    # -- Image repository
    repository: nirmata/reports-controller
    # -- (string) Image tag
    # Defaults to appVersion in Chart.yaml if omitted
    tag: ~
    # -- Image pull policy
    pullPolicy: IfNotPresent

  # -- Image pull secrets
  imagePullSecrets: []
    # - secretName

  # -- (int) Desired number of pods
  replicas: ~

  # -- Deployment update strategy.
  # Ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  # @default -- See [values.yaml](values.yaml)
  updateStrategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 40%
    type: RollingUpdate

  # -- Optional priority class
  priorityClassName: ''

  # -- Change `hostNetwork` to `true` when you want the pod to share its host's network namespace.
  # Useful for situations like when you end up dealing with a custom CNI over Amazon EKS.
  # Update the `dnsPolicy` accordingly as well to suit the host network mode.
  hostNetwork: false

  # -- `dnsPolicy` determines the manner in which DNS resolution happens in the cluster.
  # In case of `hostNetwork: true`, usually, the `dnsPolicy` is suitable to be `ClusterFirstWithHostNet`.
  # For further reference: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy.
  dnsPolicy: ClusterFirst

  # -- Extra arguments passed to the container on the command line
  extraArgs:
    clientRateLimitQPS: 300
    clientRateLimitBurst: 300
    skipResourceFilters: true

  resources:
    # -- Pod resource limits
    limits:
      memory: 128Mi
    # -- Pod resource requests
    requests:
      cpu: 100m
      memory: 64Mi

  # TODO
  # # -- Startup probe.
  # # The block is directly forwarded into the deployment, so you can use whatever startupProbes configuration you want.
  # # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  # # @default -- See [values.yaml](values.yaml)
  # startupProbe:
  #   httpGet:
  #     path: /health/liveness
  #     port: 9443
  #     scheme: HTTPS
  #   failureThreshold: 20
  #   initialDelaySeconds: 2
  #   periodSeconds: 6

  # # -- Liveness probe.
  # # The block is directly forwarded into the deployment, so you can use whatever livenessProbe configuration you want.
  # # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  # # @default -- See [values.yaml](values.yaml)
  # livenessProbe:
  #   httpGet:
  #     path: /health/liveness
  #     port: 9443
  #     scheme: HTTPS
  #   initialDelaySeconds: 15
  #   periodSeconds: 30
  #   timeoutSeconds: 5
  #   failureThreshold: 2
  #   successThreshold: 1

  # # -- Readiness Probe.
  # # The block is directly forwarded into the deployment, so you can use whatever readinessProbe configuration you want.
  # # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  # # @default -- See [values.yaml](values.yaml)
  # readinessProbe:
  #   httpGet:
  #     path: /health/readiness
  #     port: 9443
  #     scheme: HTTPS
  #   initialDelaySeconds: 5
  #   periodSeconds: 10
  #   timeoutSeconds: 5
  #   failureThreshold: 6
  #   successThreshold: 1

  # -- Node labels for pod assignment
  nodeSelector: {}

  # -- List of node taints to tolerate
  tolerations: []

  antiAffinity:
    # -- Pod antiAffinities toggle.
    # Enabled by default but can be disabled if you want to schedule pods to the same node.
    enabled: true

  # -- Pod anti affinity constraints.
  # @default -- See [values.yaml](values.yaml)
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/component
                operator: In
                values:
                  - reports-controller
          topologyKey: kubernetes.io/hostname

  # -- Pod affinity constraints.
  podAffinity: {}

  # -- Node affinity constraints.
  nodeAffinity: {}

  # -- Topology spread constraints.
  topologySpreadConstraints: []

  # -- Security context for the pod
  podSecurityContext: {}

  # -- Security context for the containers
  securityContext:
    runAsNonRoot: true
    privileged: false
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
    seccompProfile:
      type: RuntimeDefault

  podDisruptionBudget:
    enabled: false
    # -- Configures the minimum available pods for disruptions.
    # Cannot be used if `maxUnavailable` is set.
    minAvailable: 1
    # -- Configures the maximum unavailable pods for disruptions.
    # Cannot be used if `minAvailable` is set.
    maxUnavailable:

  # -- A writable volume to use for the TUF root initialization.
  tufRootMountPath: /.sigstore

  # -- Volume to be mounted in pods for TUF/cosign work.
  sigstoreVolume:
    emptyDir: {}

  metricsService:
    # -- Create service.
    create: true
    # -- Service port.
    # Metrics server will be exposed at this port.
    port: 8000
    # -- Service type.
    type: ClusterIP
    # -- (string) Service node port.
    # Only used if `type` is `NodePort`.
    nodePort: ~
    # -- Service annotations.
    annotations: {}

  networkPolicy:

    # -- When true, use a NetworkPolicy to allow ingress to the webhook
    # This is useful on clusters using Calico and/or native k8s network policies in a default-deny setup.
    enabled: false

    # -- A list of valid from selectors according to https://kubernetes.io/docs/concepts/services-networking/network-policies.
    ingressFrom: []

  serviceMonitor:
    # -- Create a `ServiceMonitor` to collect Prometheus metrics.
    enabled: false
    # -- Additional labels
    additionalLabels: {}
    # -- (string) Override namespace
    namespace: ~
    # -- Interval to scrape metrics
    interval: 30s
    # -- Timeout if metrics can't be retrieved in given time interval
    scrapeTimeout: 25s
    # -- Is TLS required for endpoint
    secure: false
    # -- TLS Configuration for endpoint
    tlsConfig: {}

  tracing:
    # -- Enable tracing
    enabled: false
    # -- (string) Traces receiver address
    address: ~
    # -- (string) Traces receiver port
    port: ~
    # -- (string) Traces receiver credentials
    creds: ~

  logging:
    # -- Logging format
    format: text

  metering:
    # -- Disable metrics export
    disabled: false
    # -- Otel configuration, can be `prometheus` or `grpc`
    config: prometheus
    # -- Prometheus endpoint port
    port: 8000
    # -- (string) Otel collector endpoint
    collector: ~
    # -- (string) Otel collector credentials
    creds: ~

# Background controller configuration
backgroundController:

  # -- Enable background controller.
  enabled: true

  rbac:
    # -- Create RBAC resources
    create: true

    serviceAccount:
      # -- Service account name
      name:

      # -- Annotations for the ServiceAccount
      annotations: {}
        # example.com/annotation: value

    clusterRole:
      # -- Extra resource permissions to add in the cluster role
      extraResources: []
      # - apiGroups:
      #     - ''
      #   resources:
      #     - pods

  image:
    # -- (string) Image registry
    registry: ~
    # If you want to manage the registry you should remove it from the repository
    # registry: ghcr.io
    # repository: nirmata/background-controller
    # -- Image repository
    repository: ghcr.io/nirmata/background-controller
    # -- Image tag
    # Defaults to appVersion in Chart.yaml if omitted
    tag:  # replaced in e2e tests
    # -- Image pull policy
    pullPolicy: IfNotPresent

  # -- Image pull secrets
  imagePullSecrets: []
    # - secretName

  # -- (int) Desired number of pods
  replicas: ~

  # -- Deployment update strategy.
  # Ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  # @default -- See [values.yaml](values.yaml)
  updateStrategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 40%
    type: RollingUpdate

  # -- Optional priority class
  priorityClassName: ''

  # -- Change `apiPriorityAndFairness` to `true` if you want to insulate the API calls made by Kyverno reports controller activities.
  # This will help ensure Kyverno reports stability in busy clusters.
  # Ref: https://kubernetes.io/docs/concepts/cluster-administration/flow-control/
  apiPriorityAndFairness: false

  # -- Priority level configuration.
  # The block is directly forwarded into the priorityLevelConfiguration, so you can use whatever specification you want.
  # ref: https://kubernetes.io/docs/concepts/cluster-administration/flow-control/#prioritylevelconfiguration
  # @default -- See [values.yaml](values.yaml)
  priorityLevelConfigurationSpec:
    type: Limited
    limited:
      nominalConcurrencyShares: 10
      limitResponse:
        queuing:
          queueLengthLimit: 50
        type: Queue

  # -- Change `hostNetwork` to `true` when you want the pod to share its host's network namespace.
  # Useful for situations like when you end up dealing with a custom CNI over Amazon EKS.
  # Update the `dnsPolicy` accordingly as well to suit the host network mode.
  hostNetwork: false

  # -- `dnsPolicy` determines the manner in which DNS resolution happens in the cluster.
  # In case of `hostNetwork: true`, usually, the `dnsPolicy` is suitable to be `ClusterFirstWithHostNet`.
  # For further reference: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy.
  dnsPolicy: ClusterFirst

  # -- Extra arguments passed to the container on the command line
  extraArgs: {}

  resources:
    # -- Pod resource limits
    limits:
      memory: 128Mi
    # -- Pod resource requests
    requests:
      cpu: 100m
      memory: 64Mi

  # -- Node labels for pod assignment
  nodeSelector: {}

  # -- List of node taints to tolerate
  tolerations: []

  antiAffinity:
    # -- Pod antiAffinities toggle.
    # Enabled by default but can be disabled if you want to schedule pods to the same node.
    enabled: true

  # -- Pod anti affinity constraints.
  # @default -- See [values.yaml](values.yaml)
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/component
                operator: In
                values:
                  - background-controller
          topologyKey: kubernetes.io/hostname

  # -- Pod affinity constraints.
  podAffinity: {}

  # -- Node affinity constraints.
  nodeAffinity: {}

  # -- Topology spread constraints.
  topologySpreadConstraints: []

  # -- Security context for the pod
  podSecurityContext: {}

  # -- Security context for the containers
  securityContext:
    runAsNonRoot: true
    privileged: false
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
    seccompProfile:
      type: RuntimeDefault

  podDisruptionBudget:
    enabled: false
    # -- Configures the minimum available pods for disruptions.
    # Cannot be used if `maxUnavailable` is set.
    minAvailable: 1
    # -- Configures the maximum unavailable pods for disruptions.
    # Cannot be used if `minAvailable` is set.
    maxUnavailable:

  metricsService:
    # -- Create service.
    create: true
    # -- Service port.
    # Metrics server will be exposed at this port.
    port: 8000
    # -- Service type.
    type: ClusterIP
    # -- Service node port.
    # Only used if `metricsService.type` is `NodePort`.
    nodePort:
    # -- Service annotations.
    annotations: {}

  networkPolicy:

    # -- When true, use a NetworkPolicy to allow ingress to the webhook
    # This is useful on clusters using Calico and/or native k8s network policies in a default-deny setup.
    enabled: false

    # -- A list of valid from selectors according to https://kubernetes.io/docs/concepts/services-networking/network-policies.
    ingressFrom: []

  serviceMonitor:
    # -- Create a `ServiceMonitor` to collect Prometheus metrics.
    enabled: false
    # -- Additional labels
    additionalLabels: {}
    # -- (string) Override namespace
    namespace: ~
    # --  Interval to scrape metrics
    interval: 30s
    # -- Timeout if metrics can't be retrieved in given time interval
    scrapeTimeout: 25s
    # -- Is TLS required for endpoint
    secure: false
    # -- TLS Configuration for endpoint
    tlsConfig: {}

  tracing:
    # -- Enable tracing
    enabled: false
    # -- Traces receiver address
    address:
    # -- Traces receiver port
    port:
    # -- Traces receiver credentials
    creds: ''

  logging:
    # -- Logging format
    format: text

  metering:
    # -- Disable metrics export
    disabled: false
    # -- Otel configuration, can be `prometheus` or `grpc`
    config: prometheus
    # -- Prometheus endpoint port
    port: 8000
    # -- Otel collector endpoint
    collector: ''
    # -- Otel collector credentials
    creds: ''

# -- Configmap storing custom CA certificate
customCAConfigMap:

# -- Path containing ssl certs within the container. Used only if customCAConfigMap is used
systemCertPath: /etc/ssl/certs

# -- License manager configs
licenseManager:
  # -- Whether to use license manager
  enable: true
  # -- License manager repo
  imageRepository: ghcr.io/nirmata/kyverno-license-manager
  # -- Image tag
  imageTag: v0.1.7
  # -- Product name to be present in license, empty to ignore check
  productName: ""
  # -- Validation interval in mins
  validateIntervalMins: 60
  # -- License server
  callHomeServer: nirmata.io
  # -- License key
  licenseKey: free-tier-license
    # -- License secret containing license string under key 'license'
  licenseSecret:
  # -- License server API key
  apiKey:
  # -- Cluster Id. If not provided, use kube-system uid
  clusterId:
  # -- Cluster name. Autogenerated if not provided
  clusterName:
